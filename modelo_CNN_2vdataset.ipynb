{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Importando los modulos necesarios"
      ],
      "metadata": {
        "id": "qWy8d-iwOcyi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalación de dependencias\n",
        "!pip install qkeras keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwEHLifdl34R",
        "outputId": "85ae6242-a012-43fc-ba88-8c8fb3f1084d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: qkeras in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.11/dist-packages (1.4.7)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from qkeras) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from qkeras) (1.14.1)\n",
            "Requirement already satisfied: pyparser in /usr/local/lib/python3.11/dist-packages (from qkeras) (1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from qkeras) (75.1.0)\n",
            "Requirement already satisfied: tensorflow-model-optimization>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from qkeras) (0.8.0)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.11/dist-packages (from qkeras) (3.4.2)\n",
            "Requirement already satisfied: scikit-learn>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from qkeras) (1.6.1)\n",
            "Requirement already satisfied: tqdm>=4.48.0 in /usr/local/lib/python3.11/dist-packages (from qkeras) (4.67.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.3)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (1.0.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.23.1->qkeras) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.23.1->qkeras) (3.5.0)\n",
            "Requirement already satisfied: absl-py~=1.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization>=0.2.1->qkeras) (1.4.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization>=0.2.1->qkeras) (0.1.9)\n",
            "Requirement already satisfied: six~=1.14 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization>=0.2.1->qkeras) (1.17.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.14.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: parse==1.6.5 in /usr/local/lib/python3.11/dist-packages (from pyparser->qkeras) (1.6.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2025.1.31)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree~=0.1.1->tensorflow-model-optimization>=0.2.1->qkeras) (25.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from dm-tree~=0.1.1->tensorflow-model-optimization>=0.2.1->qkeras) (1.17.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras-tuner) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "z0NQ9qejK1UJ"
      },
      "outputs": [],
      "source": [
        "    import h5py\n",
        "    import numpy as np\n",
        "    import json\n",
        "    import tensorflow as tf\n",
        "    from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "    from tensorflow.keras.layers import Input, MaxPooling2D, Flatten, Dropout, Add\n",
        "    from tensorflow.keras.models import Model\n",
        "    import matplotlib.pyplot as plt\n",
        "    from qkeras import *\n",
        "    import keras_tuner as kt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cargando el dataset de escalogramas"
      ],
      "metadata": {
        "id": "d0FAYi3SQCgi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "file_path = '/content/drive/MyDrive/Tesis/Accelerometer_Dataset/accelerometer_BR_256NS_20Scales_cwt_dataset.h5'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkfPdEQKQQOY",
        "outputId": "331b99a5-9d3b-4e38-cc27-f700d56676b8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_cwt_dataset(file_path='accelerometer_cwt_dataset.h5'):\n",
        "    \"\"\"\n",
        "    Carga el dataset de escalogramas desde un archivo HDF5 y lo prepara para Keras.\n",
        "\n",
        "    Args:\n",
        "        file_path: Ruta al archivo HDF5\n",
        "\n",
        "    Returns:\n",
        "        dataset: Un diccionario con los datos y metadatos\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    with h5py.File(file_path, 'r') as hf:\n",
        "        # Cargar escalogramas y etiquetas\n",
        "        x_train = np.array(hf['train']['scalograms'])\n",
        "        y_train = np.array(hf['train']['labels'])\n",
        "        x_test = np.array(hf['test']['scalograms'])\n",
        "        y_test = np.array(hf['test']['labels'])\n",
        "\n",
        "        # Cargar metadatos\n",
        "        num_classes = hf['metadata']['num_classes'][()]\n",
        "        shape = tuple(hf['metadata']['shape'][()])\n",
        "\n",
        "        # Cargar diccionario de etiquetas\n",
        "        label_codes_dict = json.loads(hf['metadata'].attrs['label_codes_dict'])\n",
        "\n",
        "    # Organizar datos como un dataset tipo Keras\n",
        "    dataset = {\n",
        "        'train': (x_train, y_train),\n",
        "        'test': (x_test, y_test),\n",
        "        'num_classes': num_classes,\n",
        "        'input_shape': shape,\n",
        "        'label_codes_dict': label_codes_dict\n",
        "    }\n",
        "\n",
        "    print(f\"Dataset cargado: {x_train.shape[0]} muestras de entrenamiento, {x_test.shape[0]} muestras de prueba\")\n",
        "    print(f\"Forma de cada escalograma: {shape}\")\n",
        "    print(f\"Número de clases: {num_classes}\")\n",
        "\n",
        "    return dataset\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "_QCaZ9PdOwpk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carga el dataset\n",
        "dataset = load_cwt_dataset(file_path)\n",
        "\n",
        "# Obtén las partes del dataset\n",
        "x_train, y_train = dataset['train']\n",
        "x_test, y_test = dataset['test']\n",
        "input_shape = dataset['input_shape']\n",
        "num_classes = dataset['num_classes']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajCrqRAcSP9k",
        "outputId": "0eaa8dda-cb7d-49ad-c6a5-52ad56154662"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset cargado: 96000 muestras de entrenamiento, 24000 muestras de prueba\n",
            "Forma de cada escalograma: (20, 256)\n",
            "Número de clases: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preparar las etiquetas con one-hot encoding"
      ],
      "metadata": {
        "id": "wVbk7WdRYJqD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir etiquetas a formato one-hot\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Verificar la forma actual de las etiquetas\n",
        "print(\"Forma original de y_train:\", y_train.shape)\n",
        "print(\"Primeros 5 valores de y_train:\", y_train[:5])\n",
        "\n",
        "# Convertir etiquetas a formato one-hot\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)\n",
        "\n",
        "# Verificar la nueva forma\n",
        "print(\"Nueva forma de y_train:\", y_train.shape)\n",
        "print(\"Primeros 5 valores de y_train:\", y_train[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liggasglYS68",
        "outputId": "ce161c66-6d36-4f92-cd88-530f42614f28"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forma original de y_train: (96000,)\n",
            "Primeros 5 valores de y_train: [4 0 4 2 2]\n",
            "Nueva forma de y_train: (96000, 5)\n",
            "Primeros 5 valores de y_train: [[0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Verificando la normalización de los datos"
      ],
      "metadata": {
        "id": "F0-d98e7aDvU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar si los datos ya están normalizados\n",
        "print(\"Estado actual de los datos:\")\n",
        "print(\"Valor máximo en x_train:\", np.max(x_train))\n",
        "print(\"Valor mínimo en x_train:\", np.min(x_train))\n",
        "print(\"Media de x_train:\", np.mean(x_train))\n",
        "print(\"Desviación estándar de x_train:\", np.std(x_train))\n",
        "\n",
        "# Visualizar la distribución de valores\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.hist(x_train.flatten(), bins=50)\n",
        "plt.title('Distribución de valores en x_train')\n",
        "plt.xlabel('Valor')\n",
        "plt.ylabel('Frecuencia')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "id": "jHGpULI8aK3K",
        "outputId": "8b491c50-7f9b-4153-c8ce-ece913fb21c8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estado actual de los datos:\n",
            "Valor máximo en x_train: 22.972864\n",
            "Valor mínimo en x_train: 1.7875869e-10\n",
            "Media de x_train: 0.18690377\n",
            "Desviación estándar de x_train: 0.49832457\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#No estan normalizado, a normalizar!!"
      ],
      "metadata": {
        "id": "Sounit5YbD9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizar los datos de entrada usando el máximo de x_train para ambos conjuntos\n",
        "max_value = np.max(x_train)  # Usar sólo el conjunto de entrenamiento para calcular el valor\n",
        "\n",
        "# Convertir a float32 y normalizar\n",
        "x_train = x_train.astype('float32') / max_value\n",
        "x_test = x_test.astype('float32') / max_value  # Usar el mismo valor para test\n",
        "\n",
        "print(\"Después de normalizar:\")\n",
        "print(\"Valor máximo en x_train:\", np.max(x_train))\n",
        "print(\"Valor mínimo en x_train:\", np.min(x_train))\n",
        "print(\"Valor máximo en x_test:\", np.max(x_test))\n",
        "print(\"Valor mínimo en x_test:\", np.min(x_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BW311Ut4bJ6C",
        "outputId": "d932cf76-4a8d-402b-daa4-6d9dd1cf8776"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Después de normalizar:\n",
            "Valor máximo en x_train: 1.0\n",
            "Valor mínimo en x_train: 7.781297e-12\n",
            "Valor máximo en x_test: 0.37690073\n",
            "Valor mínimo en x_test: 1.8382905e-11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Adaptando los datos para el modelo CNN"
      ],
      "metadata": {
        "id": "OQnhPxKrcfjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Forma de x_train:\", x_train.shape)\n",
        "print(\"Forma de y_train:\", y_train.shape)\n",
        "print(\"Forma de x_test:\", x_test.shape)\n",
        "print(\"Forma de y_test:\", y_test.shape)\n",
        "# Adaptar dimensiones para CNN (necesitamos un canal)\n",
        "# Asumiendo que las dimensiones actuales son (n_samples, scales, time_steps)\n",
        "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)\n",
        "\n",
        "print(\"Forma final de x_train:\", x_train.shape)\n",
        "print(\"Forma final de x_test:\", x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ig1FtbvWcCWS",
        "outputId": "23c038d5-cc78-480e-c86e-d1f01f28b34a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forma de x_train: (96000, 20, 256)\n",
            "Forma de y_train: (96000, 5)\n",
            "Forma de x_test: (24000, 20, 256)\n",
            "Forma de y_test: (24000, 5)\n",
            "Forma final de x_train: (96000, 20, 256, 1)\n",
            "Forma final de x_test: (24000, 20, 256, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Separamos una parte de los datos para la validacion del modelo"
      ],
      "metadata": {
        "id": "vZbtscxMdrkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Dividir los datos\n",
        "x_train_final, x_val, y_train_final, y_val = train_test_split(\n",
        "    x_train, y_train,\n",
        "    test_size=0.2,  # 20% para validación\n",
        "    random_state=42,  # Para reproducibilidad\n",
        "    stratify=y_train  # Mantener la distribución de clases\n",
        ")\n",
        "\n",
        "# Verificar tamaños\n",
        "print(f\"Datos de entrenamiento: {x_train_final.shape[0]} muestras\")\n",
        "print(f\"Datos de validación: {x_val.shape[0]} muestras\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHz0TrT6dz_N",
        "outputId": "bb0b59d8-ae20-4205-d6ed-6d999e3b777b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datos de entrenamiento: 76800 muestras\n",
            "Datos de validación: 19200 muestras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definiendo los bloques convolucionales de mi modelo"
      ],
      "metadata": {
        "id": "iyc4e56ZrmTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_qconv_block(inputs, filters, kernel_size=3, strides=1,\n",
        "                     use_residual=True, use_maxpool=False):\n",
        "    \"\"\"\n",
        "    Bloque convolucional compatible con STM32\n",
        "    \"\"\"\n",
        "    # Para capas intermedias, usar binary(alpha=1) para tipo s1\n",
        "    x = QConv2D(filters=filters,\n",
        "                kernel_size=kernel_size,\n",
        "                strides=strides,\n",
        "                padding='same',\n",
        "                kernel_quantizer=\"binary(alpha=1)\",\n",
        "                bias_quantizer=\"binary(alpha=1)\",\n",
        "                use_bias=False)(inputs)\n",
        "\n",
        "    # MaxPool antes de BatchNorm (como en el snippet)\n",
        "    if use_maxpool:\n",
        "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    x = QBatchNormalization()(x)\n",
        "    x = QActivation(\"binary(alpha=1)\")(x)\n",
        "\n",
        "    # Conexión residual cuando sea posible\n",
        "    if use_residual and strides == 1 and inputs.shape[-1] == filters:\n",
        "        return Add()([inputs, x])\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "IdsoqRqUrtKi"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Función NAS con Keras Tuner"
      ],
      "metadata": {
        "id": "Y5LFHHMfyIzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_builder(hp):\n",
        "    \"\"\"\n",
        "    Función de construcción de modelo para Keras Tuner\n",
        "    Con cuantizaciones específicas compatibles con STM32\n",
        "    \"\"\"\n",
        "    # Definir rangos de hiperparámetros\n",
        "    conv_stages = hp.Int('conv_stages', min_value=2, max_value=4, step=1)\n",
        "    initial_filters = hp.Choice('initial_filters', values=[32, 64])\n",
        "    growth_rate = hp.Choice('growth_rate', values=[1.5, 2.0])\n",
        "    dropout_rate = hp.Float('dropout_rate', min_value=0.0, max_value=0.5, step=0.1)\n",
        "\n",
        "    # Opciones de cuantización compatibles con STM32\n",
        "    # Solo exploramos s8, s1 y f32\n",
        "    layer_precision = hp.Choice('layer_precision', values=[\n",
        "        's1',  # Binario para capas internas\n",
        "        's8',  # 8 bits con signo para mayor precisión\n",
        "    ])\n",
        "\n",
        "    # Mapeo de opciones de precisión a cuantizadores específicos\n",
        "    quantizer_map = {\n",
        "        's1': \"binary(alpha=1)\",\n",
        "        's8': \"quantized_bits(8,0,1)\",\n",
        "    }\n",
        "\n",
        "    # Seleccionar cuantizadores basados en la precisión elegida\n",
        "    hidden_kernel_quantizer = quantizer_map[layer_precision]\n",
        "    hidden_activation = \"binary(alpha=1)\" if layer_precision == 's1' else \"quantized_relu(8)\"\n",
        "\n",
        "    # Primera y última capa siempre con mayor precisión (s8)\n",
        "    first_layer_quantizer = \"quantized_bits(8,0,1)\"\n",
        "    last_layer_quantizer = \"quantized_bits(8,0,1)\"\n",
        "\n",
        "    # Asegurar que el número de canales sea múltiplo de 32 (recomendado para STM32)\n",
        "    def round_filters(filters):\n",
        "        return 32 * max(1, round(filters / 32))\n",
        "\n",
        "    # Input layer\n",
        "    inputs = Input(shape=(x_train_final.shape[1], x_train_final.shape[2], 1))\n",
        "\n",
        "    # Primera capa con mayor precisión (s8)\n",
        "    x = QConv2D(filters=round_filters(initial_filters),\n",
        "                kernel_size=3,\n",
        "                padding='same',\n",
        "                kernel_quantizer=first_layer_quantizer,\n",
        "                bias_quantizer=first_layer_quantizer)(inputs)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = QBatchNormalization()(x)\n",
        "    x = QActivation(\"quantized_relu(8)\")(x)\n",
        "\n",
        "    # Bloques intermedios con escalado progresivo\n",
        "    filters = initial_filters\n",
        "\n",
        "    for i in range(conv_stages):\n",
        "        # Escalar progresivamente - más bloques en etapas posteriores\n",
        "        num_blocks = 1 + i  # 1, 2, 3... bloques por etapa\n",
        "        filters = round_filters(filters * growth_rate)\n",
        "\n",
        "        for j in range(num_blocks):\n",
        "            use_residual = j > 0 and layer_precision != 's1'  # Las capas binarias a veces no funcionan bien con residuales\n",
        "            strides = 1\n",
        "            use_maxpool = (j == num_blocks-1) and (i < conv_stages-1)\n",
        "\n",
        "            # Definir el uso de bias según la cuantización\n",
        "            use_bias = layer_precision != 's1'  # Capas binarias generalmente sin bias\n",
        "\n",
        "            # Capa convolucional con cuantización seleccionada\n",
        "            x_input = x\n",
        "            x = QConv2D(filters=filters,\n",
        "                     kernel_size=3,\n",
        "                     strides=strides,\n",
        "                     padding='same',\n",
        "                     kernel_quantizer=hidden_kernel_quantizer,\n",
        "                     bias_quantizer=hidden_kernel_quantizer if use_bias else None,\n",
        "                     use_bias=use_bias)(x)\n",
        "\n",
        "            # MaxPool antes de BatchNorm (recomendado para STM32)\n",
        "            if use_maxpool:\n",
        "                x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "            x = QBatchNormalization()(x)\n",
        "            x = QActivation(hidden_activation)(x)\n",
        "\n",
        "            # Conexión residual cuando sea posible\n",
        "            if use_residual and strides == 1 and x_input.shape[-1] == filters:\n",
        "                x = Add()([x_input, x])\n",
        "\n",
        "            # Aplicar Dropout después de cada bloque (excepto el último)\n",
        "            if i < conv_stages - 1 or j < num_blocks - 1:\n",
        "                x = Dropout(dropout_rate)(x)\n",
        "\n",
        "    # Flatten\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    # Capas densas finales con s8\n",
        "    x = QDense(round_filters(128),\n",
        "               kernel_quantizer=last_layer_quantizer,\n",
        "               bias_quantizer=last_layer_quantizer)(x)\n",
        "    x = QBatchNormalization()(x)\n",
        "    x = QActivation(\"quantized_relu(8)\")(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "\n",
        "    # Capa de salida (5 clases) - mantener en alta precisión (s8)\n",
        "    outputs = QDense(5,\n",
        "                    kernel_quantizer=last_layer_quantizer,\n",
        "                    bias_quantizer=last_layer_quantizer,\n",
        "                    activation=\"softmax\")(x)\n",
        "\n",
        "    # Crear y compilar modelo\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    # Configurar optimizador con tasa de aprendizaje adaptable\n",
        "    lr = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "lsS7v2PL0L5k"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definiendo mi metrica compuesta para seleccionar los modelos"
      ],
      "metadata": {
        "id": "a_2l9Xkw3_h-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class STM32TunerMultiObjective(kt.BayesianOptimization):\n",
        "    def __init__(self, *args,\n",
        "                 accuracy_weight=0.6,\n",
        "                 model_size_weight=0.2,\n",
        "                 ram_usage_weight=0.2,\n",
        "                 max_parameters=100000,\n",
        "                 max_ram_kb=48,  # Dejamos margen de seguridad para STM32L432KC (64KB total)\n",
        "                 **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.accuracy_weight = accuracy_weight\n",
        "        self.model_size_weight = model_size_weight\n",
        "        self.ram_usage_weight = ram_usage_weight\n",
        "        self.max_parameters = max_parameters\n",
        "        self.max_ram_kb = max_ram_kb\n",
        "\n",
        "    def run_trial(self, trial, *args, **kwargs):\n",
        "        hp = trial.hyperparameters\n",
        "        model = self.hypermodel.build(hp)\n",
        "\n",
        "        # 1. Evaluar tamaño del modelo\n",
        "        total_params = model.count_params()\n",
        "\n",
        "        # 2. Estimar uso de RAM (heurística aproximada)\n",
        "        # Para modelos cuantizados en STM32, estimamos en base a parámetros y arquitectura\n",
        "        ram_usage_kb = self.estimate_ram_usage(model, hp)\n",
        "\n",
        "        # Si excede los límites, rechazar directamente\n",
        "        if total_params > self.max_parameters or ram_usage_kb > self.max_ram_kb:\n",
        "            print(f\"Modelo rechazado: Params={total_params}, RAM={ram_usage_kb}KB\")\n",
        "            return {\"status\": kt.engine.trial.TrialStatus.INVALID}\n",
        "\n",
        "        # Ejecutar entrenamiento normal\n",
        "        results = super(STM32TunerMultiObjective, self).run_trial(trial, *args, **kwargs)\n",
        "\n",
        "        if results[\"status\"] != kt.engine.trial.TrialStatus.OK:\n",
        "            return results\n",
        "\n",
        "        # Obtener precisión\n",
        "        val_accuracy = results[\"metrics\"][\"val_accuracy\"]\n",
        "\n",
        "        # Calcular puntuación normalizada para cada objetivo\n",
        "        accuracy_score = val_accuracy  # Ya está entre 0-1\n",
        "\n",
        "        # Normalizar tamaño del modelo (invertido: más pequeño es mejor)\n",
        "        size_score = 1.0 - (total_params / self.max_parameters)\n",
        "\n",
        "        # Normalizar uso de RAM (invertido: más pequeño es mejor)\n",
        "        ram_score = 1.0 - (ram_usage_kb / self.max_ram_kb)\n",
        "\n",
        "        # Calcular puntuación compuesta\n",
        "        composite_score = (\n",
        "            self.accuracy_weight * accuracy_score +\n",
        "            self.model_size_weight * size_score +\n",
        "            self.ram_usage_weight * ram_score\n",
        "        )\n",
        "\n",
        "        # Mostrar información detallada\n",
        "        print(f\"\\nModelo evaluado:\")\n",
        "        print(f\"- Precisión: {val_accuracy:.4f} → Score: {accuracy_score:.4f}\")\n",
        "        print(f\"- Parámetros: {total_params:,} → Score: {size_score:.4f}\")\n",
        "        print(f\"- RAM est.: {ram_usage_kb:.1f}KB → Score: {ram_score:.4f}\")\n",
        "        print(f\"- Puntuación total: {composite_score:.4f}\\n\")\n",
        "\n",
        "        # Sobreescribir la métrica objetivo con nuestra puntuación compuesta\n",
        "        results[\"score\"] = composite_score\n",
        "        return results\n",
        "\n",
        "    def estimate_ram_usage(self, model, hp):\n",
        "        \"\"\"\n",
        "        Estima uso de RAM en KB durante inferencia, específico para STM32\n",
        "        \"\"\"\n",
        "        # Configuración del modelo\n",
        "        layer_precision = hp.get('layer_precision', 's8')\n",
        "        total_params = model.count_params()\n",
        "\n",
        "        # Calcular número aproximado de activaciones\n",
        "        activation_memory = 0\n",
        "        intermediate_shapes = []\n",
        "\n",
        "        # Calculamos formas intermedias para estimar\n",
        "        x = tf.keras.layers.Input(shape=(x_train_final.shape[1], x_train_final.shape[2], 1))\n",
        "        for layer in model.layers[1:]:  # Saltamos la capa de entrada\n",
        "            if hasattr(layer, 'input_shape') and hasattr(layer, 'output_shape'):\n",
        "                if isinstance(layer.output_shape, tuple):\n",
        "                    shape = layer.output_shape[1:]  # Ignorar dimensión de batch\n",
        "                    size = np.prod(shape)\n",
        "                    intermediate_shapes.append(size)\n",
        "\n",
        "        # Bits por activación según precisión\n",
        "        bits_per_activation = 1 if layer_precision == 's1' else 8\n",
        "\n",
        "        # Estimamos memoria para activaciones (factor de ajuste empírico)\n",
        "        activation_memory = sum(intermediate_shapes) * bits_per_activation / 8 / 1024\n",
        "\n",
        "        # Memoria para parámetros del modelo\n",
        "        if layer_precision == 's1':\n",
        "            # Modelos binarios son muy eficientes en memoria\n",
        "            params_memory = total_params * 1 / 8 / 1024  # 1 bit por parámetro\n",
        "        else:\n",
        "            # s8 usa 8 bits por parámetro\n",
        "            params_memory = total_params * 8 / 8 / 1024\n",
        "\n",
        "        # Memoria para buffers de trabajo (estimación)\n",
        "        working_memory = 10  # ~10KB base aproximada para STM32Cube.AI runtime\n",
        "\n",
        "        # Total memoria estimada\n",
        "        total_memory = params_memory + activation_memory + working_memory\n",
        "\n",
        "        return total_memory"
      ],
      "metadata": {
        "id": "BXgr9Ysy4KYg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejecución de la búsqueda de la arquitectura"
      ],
      "metadata": {
        "id": "fvSsrL0e4P5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_nas():\n",
        "    \"\"\"\n",
        "    Ejecuta la búsqueda de arquitectura con criterios balanceados para STM32\n",
        "    \"\"\"\n",
        "    # Usar nuestro Tuner personalizado con pesos configurables para cada objetivo\n",
        "    tuner = STM32TunerMultiObjective(\n",
        "        model_builder,\n",
        "        objective='val_accuracy',  # Seguimos necesitando esto como referencia\n",
        "        max_trials=30,\n",
        "        directory='nas_results',\n",
        "        project_name='dqnn_escalogramas_stm32',\n",
        "        # Configuración de pesos para balancear los objetivos\n",
        "        accuracy_weight=0.6,     # 60% importancia a precisión\n",
        "        model_size_weight=0.2,   # 20% importancia a tamaño de modelo\n",
        "        ram_usage_weight=0.2,    # 20% importancia a uso de RAM\n",
        "        # Límites específicos para STM32L432KC\n",
        "        max_parameters=100000,   # Límite de parámetros\n",
        "        max_ram_kb=48            # Límite de RAM en KB (con margen)\n",
        "    )\n",
        "\n",
        "    # Resto del código igual...\n",
        "    callbacks = [\n",
        "        EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "        ReduceLROnPlateau(factor=0.2, patience=5)\n",
        "    ]\n",
        "\n",
        "    # Ejecutar búsqueda (igual)\n",
        "    tuner.search(\n",
        "        x_train_final, y_train_final,\n",
        "        validation_data=(x_val, y_val),\n",
        "        epochs=50,\n",
        "        batch_size=64,\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "\n",
        "    # Obtener mejor modelo según puntuación compuesta\n",
        "    best_model = tuner.get_best_models(1)[0]\n",
        "    best_hps = tuner.get_best_hyperparameters(1)[0]\n",
        "\n",
        "    # Mostrar detalles del mejor modelo\n",
        "    print(\"\\n=== MEJOR MODELO ENCONTRADO ===\")\n",
        "    print(f\"Etapas convolucionales: {best_hps.get('conv_stages')}\")\n",
        "    print(f\"Filtros iniciales: {best_hps.get('initial_filters')}\")\n",
        "    print(f\"Tasa de crecimiento: {best_hps.get('growth_rate')}\")\n",
        "    print(f\"Precisión de capa: {best_hps.get('layer_precision')}\")\n",
        "    print(f\"Total parámetros: {best_model.count_params():,}\")\n",
        "\n",
        "    # Estimar huella de memoria\n",
        "    ram_usage = tuner.estimate_ram_usage(best_model, best_hps)\n",
        "    print(f\"RAM estimada: {ram_usage:.2f} KB\")\n",
        "\n",
        "    return best_model, best_hps"
      ],
      "metadata": {
        "id": "MLOGvCGv4a9L"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenamiento y evaluación"
      ],
      "metadata": {
        "id": "3cOGw1Vi5hGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Ejecutar NAS\n",
        "best_model, best_hps = run_nas()\n",
        "\n",
        "# Entrenar mejor modelo con toda la configuración\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=15, restore_best_weights=True),\n",
        "    ReduceLROnPlateau(factor=0.1, patience=7),\n",
        "    ModelCheckpoint('best_dqnn_model.h5', save_best_only=True)\n",
        "]\n",
        "\n",
        "history = best_model.fit(\n",
        "    x_train_final, y_train_final,\n",
        "    validation_data=(x_val, y_val),\n",
        "    epochs=100,\n",
        "    batch_size=64,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# Evaluar modelo\n",
        "test_loss, test_acc = best_model.evaluate(x_test, y_test)\n",
        "print(f\"Precisión en conjunto de prueba: {test_acc:.4f}\")\n",
        "\n",
        "# Visualizar\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Precisión del modelo')\n",
        "plt.ylabel('Precisión')\n",
        "plt.xlabel('Época')\n",
        "plt.legend(['Train', 'Validación'], loc='lower right')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Pérdida del modelo')\n",
        "plt.ylabel('Pérdida')\n",
        "plt.xlabel('Época')\n",
        "plt.legend(['Train', 'Validación'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "Xn5icfPf5yVc",
        "outputId": "ae4df10f-9c9d-444b-94ac-4e7bf9ae7941"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Unrecognized keyword arguments passed to QBatchNormalization: {'fused': False, 'renorm': False, 'virtual_batch_size': None, 'adjustment': None}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-5ddc1f8c9ee9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Ejecutar NAS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_hps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_nas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Entrenar mejor modelo con toda la configuración\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m callbacks = [\n",
            "\u001b[0;32m<ipython-input-14-0e10c832552a>\u001b[0m in \u001b[0;36mrun_nas\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \"\"\"\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Usar nuestro Tuner personalizado con pesos configurables para cada objetivo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     tuner = STM32TunerMultiObjective(\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mmodel_builder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mobjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Seguimos necesitando esto como referencia\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-443cf19588ca>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, accuracy_weight, model_size_weight, ram_usage_weight, max_parameters, max_ram_kb, *args, **kwargs)\u001b[0m\n\u001b[1;32m      7\u001b[0m                  \u001b[0mmax_ram_kb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m48\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Dejamos margen de seguridad para STM32L432KC (64KB total)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                  **kwargs):\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_size_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_size_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras_tuner/src/tuners/bayesian.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, hypermodel, objective, max_trials, num_initial_points, alpha, beta, seed, hyperparameters, tune_new_entries, allow_new_entries, max_retries_per_trial, max_consecutive_failed_trials, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0mmax_consecutive_failed_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_consecutive_failed_trials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         )\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypermodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras_tuner/src/engine/tuner.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, oracle, hypermodel, max_model_size, optimizer, loss, metrics, distribution_strategy, directory, project_name, logger, tuner_id, overwrite, executions_per_trial, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             )\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    123\u001b[0m             \u001b[0moracle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mhypermodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras_tuner/src/engine/base_tuner.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, oracle, hypermodel, directory, project_name, overwrite, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;31m# Only populate initial space if not reloading.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_populate_initial_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;31m# Run in distributed mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras_tuner/src/engine/base_tuner.py\u001b[0m in \u001b[0;36m_populate_initial_space\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeclare_hyperparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activate_all_conditions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras_tuner/src/engine/base_tuner.py\u001b[0m in \u001b[0;36m_activate_all_conditions\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-ef3bf107550a>\u001b[0m in \u001b[0;36mmodel_builder\u001b[0;34m(hp)\u001b[0m\n\u001b[1;32m     45\u001b[0m                 bias_quantizer=first_layer_quantizer)(inputs)\n\u001b[1;32m     46\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"quantized_relu(8)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/qkeras/qnormalization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, axis, momentum, epsilon, center, scale, activation, beta_initializer, gamma_initializer, moving_mean_initializer, moving_variance_initializer, beta_regularizer, gamma_regularizer, beta_quantizer, gamma_quantizer, mean_quantizer, variance_quantizer, gamma_constraint, beta_constraint, beta_range, gamma_range, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'adjustment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m     super(QBatchNormalization, self).__init__(\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/normalization/batch_normalization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, axis, momentum, epsilon, center, scale, beta_initializer, gamma_initializer, moving_mean_initializer, moving_variance_initializer, beta_regularizer, gamma_regularizer, beta_constraint, gamma_constraint, synchronized, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     ):\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, activity_regularizer, trainable, dtype, autocast, name, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_shape_arg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape_arg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    288\u001b[0m                 \u001b[0;34m\"Unrecognized keyword arguments \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m                 \u001b[0;34mf\"passed to {self.__class__.__name__}: {kwargs}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unrecognized keyword arguments passed to QBatchNormalization: {'fused': False, 'renorm': False, 'virtual_batch_size': None, 'adjustment': None}"
          ]
        }
      ]
    }
  ]
}